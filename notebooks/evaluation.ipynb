{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc90d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_data, read_data\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b457fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperseek_files = glob(\"ablation/final/**\")\n",
    "eval_df = pd.read_excel(\"data/eval_cps.xlsx\")\n",
    "query_df = pd.read_excel(\"data/slr_query_results.xlsx\")\n",
    "query_topics = set(query_df[\"topic\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cfce263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slr_query_results_count(topic: str, top_n=10_000) -> int:\n",
    "    \"\"\"If the topic has a query then return the number of results the query had.\"\"\"\n",
    "    if topic in query_df[\"topic\"].unique().tolist():\n",
    "        return min(query_df[query_df[\"topic\"] == topic].shape[0], top_n)\n",
    "    else:\n",
    "        return top_n\n",
    "\n",
    "def get_slr_query_results(df: pd.DataFrame, topics: list[str]) -> dict[str, float]:\n",
    "    results = {}\n",
    "    for topic in topics:\n",
    "        ids = df[(df[\"topic\"] == topic) & (df[\"is_core\"])][\"id\"].to_list()\n",
    "        topic_df = eval_df[eval_df[\"topic\"] == topic]\n",
    "        n_cores = topic_df.loc[eval_df[\"id\"].isin(ids)][\"title\"].count().item()\n",
    "        actual = topic_df.shape[0]\n",
    "        results[topic] = n_cores / actual\n",
    "    return results\n",
    "\n",
    "def get_paperseek_results(dfs: list[pd.DataFrame], limit_k: bool = False) -> dict[str, float]:\n",
    "    results = {}\n",
    "    for df in dfs:\n",
    "        for topic in df[\"topic\"].unique():\n",
    "            topic_df = eval_df[eval_df[\"topic\"] == topic]\n",
    "            ids = (\n",
    "                df[df[\"topic\"] == topic]\n",
    "                .sort_values(\"score\", ascending=False)[\"id\"]\n",
    "                .tolist()\n",
    "            )\n",
    "            if limit_k:\n",
    "                top_n = slr_query_results_count(topic)\n",
    "                ids = ids[:top_n]\n",
    "                \n",
    "            n_cores = topic_df.loc[eval_df[\"id\"].isin(ids)][\"title\"].count().item()\n",
    "            actual = topic_df.shape[0]\n",
    "            if topic in results:\n",
    "                results[topic].append(n_cores / actual)\n",
    "            else:\n",
    "                results[topic] = [n_cores / actual]\n",
    "    return {k: np.mean(v) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb80481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_results(limit_k: bool, files: list[str], filename: str) -> None:\n",
    "    slr_query_results = get_slr_query_results(query_df, query_topics)\n",
    "    paperseek_results = get_paperseek_results(\n",
    "        [pd.read_parquet(file) for file in files], limit_k\n",
    "    )\n",
    "    results_df = pd.merge(\n",
    "        pd.DataFrame.from_dict(\n",
    "            paperseek_results, orient=\"index\", columns=[\"paperseek_results\"]\n",
    "        ),\n",
    "        pd.DataFrame.from_dict(\n",
    "            slr_query_results, orient=\"index\", columns=[\"slr_query_results\"]\n",
    "        ),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how=\"outer\",\n",
    "    )\n",
    "    results_df[\"Sample Size\"] = results_df.index.map(\n",
    "        lambda x: slr_query_results_count(x)\n",
    "    )\n",
    "    save_data(results_df.reset_index(names=\"Topic\"), filename)\n",
    "\n",
    "\n",
    "def store_optimzed_results(limit_k=True) -> None:\n",
    "    # The recall is calcuated based on the top k results of the respective SLR query\n",
    "    store_results(\n",
    "        limit_k=limit_k,\n",
    "        files=paperseek_files,\n",
    "        filename=\"post_input_optimization_results_by_k\" if limit_k else \"post_input_optimization_results_10k\",\n",
    "    )\n",
    "\n",
    "def store_synthetic_cp_results(limit_k=False) -> None:\n",
    "    store_results(\n",
    "        limit_k=limit_k,\n",
    "        files=[r\"ablation\\All_HYDE0_SYNTHETIC_CORE.parquet\"],\n",
    "        filename=\"synthetic_core_results_by_k\" if limit_k else \"synthetic_core_results_10k\",\n",
    "    )\n",
    "    \n",
    "def store_baseline_results(limit_k= False) -> None:\n",
    "    # The recall is calculated based on the top 10k results of the respective SLR query\n",
    "    store_results(\n",
    "        limit_k=limit_k,\n",
    "        files=[r\"ablation\\All_HYDE0_notext.parquet\"],\n",
    "        filename=\"baseline_results_by_k\" if limit_k else \"baseline_results_10k\",\n",
    "    )\n",
    "\n",
    "# store_optimzed_results()\n",
    "store_synthetic_cp_results(True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
