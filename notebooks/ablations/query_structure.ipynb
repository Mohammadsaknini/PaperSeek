{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study for PaperSeek\n",
    "\n",
    "This notebook presents an ablation study for the PaperSeek pipeline, examining how different input query structures affect the retrieval performance across various scientific topics.\n",
    "\n",
    "1. The impact of different research question counts.\n",
    "2. The impact of adding sub ressearch questions to the query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.ablations.utils import select_core_pub\n",
    "from utils import DataReader, Query\n",
    "from itertools import product\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "core_df = pd.read_excel(\"data/eval_cps.xlsx\")\n",
    "df_random = pd.read_excel(\"ablation/query_combinations/random_cp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ablation(topics, core_type: Literal[\"worst\", \"average\", \"best\", \"random\"] = \"average\"):\n",
    "    n_rq = [1, 3, 5, 100]\n",
    "    has_text = [True, False]\n",
    "    include_sub_rq = [True, False]\n",
    "\n",
    "    combinations = list(product(n_rq, has_text, include_sub_rq))\n",
    "    core_pubs, texts, topics = select_core_pub(topics, type=core_type)\n",
    "    reader = DataReader(create_index=False)\n",
    "    results = {\n",
    "        (rq_count, has_text, include_sub_rq): {}\n",
    "        for rq_count, has_text, include_sub_rq in combinations\n",
    "    }\n",
    "    queries = []\n",
    "    for text, topic in zip(texts, topics):\n",
    "        for rq_count, has_text, include_sub_rq in combinations:\n",
    "            queries.append(\n",
    "                Query(topic).format(\n",
    "                    rq_count=rq_count,\n",
    "                    include_sub_rq=include_sub_rq,\n",
    "                    supporting_texts=text if has_text else None,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    hits = reader.fetch(queries)\n",
    "    idx = 0\n",
    "    n_combs = len(combinations)\n",
    "    for i, hit in enumerate(hits):\n",
    "        cycle_idx = i % n_combs # every 16 iteartions occurs a new topic\n",
    "        if i > 0 and cycle_idx == 0:\n",
    "            idx += 1\n",
    "        rq_count, has_text, include_sub_rq =combinations[cycle_idx]\n",
    "        topic_df = core_df[core_df[\"topic\"] == topics[idx]]\n",
    "        n_cores = topic_df[core_df[\"id\"].isin(hit.ids)][\"title\"].count()\n",
    "        actual = topic_df.shape[0]\n",
    "        results[(rq_count, has_text, include_sub_rq)][topics[idx]] = n_cores / actual\n",
    "    return results\n",
    "\n",
    "\n",
    "def run():\n",
    "    topics = core_df[\"topic\"].unique()\n",
    "\n",
    "    pd.DataFrame(run_ablation(topics, \"worst\")).T.reset_index().rename(\n",
    "        columns={\n",
    "            \"level_0\": \"rq_count\",\n",
    "            \"level_1\": \"has_text\",\n",
    "            \"level_2\": \"include_sub_rq\",\n",
    "        }\n",
    "    ).to_excel(\"ablation/query_combinations/worst_cp.xlsx\", index=False)\n",
    "\n",
    "    pd.DataFrame(run_ablation(topics, \"average\")).T.reset_index().rename(\n",
    "        columns={\n",
    "            \"level_0\": \"rq_count\",\n",
    "            \"level_1\": \"has_text\",\n",
    "            \"level_2\": \"include_sub_rq\",\n",
    "        }\n",
    "    ).to_excel(\"ablation/query_combinations/avg_cp.xlsx\", index=False)\n",
    "\n",
    "    pd.DataFrame(run_ablation(topics, \"best\")).T.reset_index().rename(\n",
    "        columns={\n",
    "            \"level_0\": \"rq_count\",\n",
    "            \"level_1\": \"has_text\",\n",
    "            \"level_2\": \"include_sub_rq\",\n",
    "        }\n",
    "    ).to_excel(\"ablation/query_combinations/best_cp.xlsx\", index=False)\n",
    "\n",
    "    pd.DataFrame(run_ablation(topics, \"random\")).T.reset_index().rename(\n",
    "        columns={\n",
    "            \"level_0\": \"rq_count\",\n",
    "            \"level_1\": \"has_text\",\n",
    "            \"level_2\": \"include_sub_rq\",\n",
    "        }\n",
    "    ).to_excel(\"ablation/query_combinations/random_cp.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subrqs_vs_without(df: pd.DataFrame):\n",
    "    print(\"The average recall of the queries with and without sub-RQs\")\n",
    "    clms = list(set(df.columns).difference(set([\"rq_count\", \"has_text\"])))\n",
    "    df = (\n",
    "        df[~df[\"has_text\"]][clms]\n",
    "        .groupby(\"include_sub_rq\")\n",
    "        .mean()\n",
    "        .mean(axis=1)\n",
    "        .to_frame()\n",
    "        .reset_index().T\n",
    "    )\n",
    "    display(df.rename(columns=df.iloc[0]).iloc[1:])\n",
    "\n",
    "def one_or_many_RQs(df: pd.DataFrame):\n",
    "    print(\"The average recall of the queries using 1, 3, 5 or 100 RQs\")\n",
    "    clms = list(set(df.columns).difference(set([\"has_text\", \"include_sub_rq\"])))\n",
    "    df = (\n",
    "        df[~df[\"has_text\"]][clms]\n",
    "        .groupby(\"rq_count\")\n",
    "        .mean()\n",
    "        .mean(axis=1)\n",
    "        .to_frame()\n",
    "        .reset_index().T\n",
    "    )\n",
    "    display(df.rename(columns=df.iloc[0]).iloc[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average recall of the queries with and without sub-RQs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754831</td>\n",
       "      <td>0.753443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      False     True \n",
       "0  0.754831  0.753443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subrqs_vs_without(df_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average recall of the queries using 1, 3, 5 or 100 RQs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>100.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750005</td>\n",
       "      <td>0.755402</td>\n",
       "      <td>0.756034</td>\n",
       "      <td>0.755108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1.0       3.0       5.0       100.0\n",
       "0  0.750005  0.755402  0.756034  0.755108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_or_many_RQs(df_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
