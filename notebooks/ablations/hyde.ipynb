{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study for PaperSeek\n",
    "\n",
    "This notebook presents an ablation study for the PaperSeek pipeline, examining how adding additional synthetic CPs affect the retrieval performance across various scientific topics.\n",
    "\n",
    "1. The effect of rerankers on retrieval performance using differnet number of HyDe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks.ablations.utils import TOPICS_UNDER_10K\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from textwrap import shorten\n",
    "import plotly.express as px\n",
    "from glob import glob\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "eval_df = pd.read_excel(\"data/eval_cps.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(files: list[str], under_10k: bool, top_n: int) -> pd.DataFrame:\n",
    "    results = defaultdict(list)\n",
    "    for file in files:\n",
    "        df = pd.read_parquet(file)\n",
    "        topics = list(TOPICS_UNDER_10K) if under_10k else df[\"topic\"].unique()\n",
    "        if \"HYDE\" in file:\n",
    "            hyde_n = file.split(\"_HYDE\")[1][0]\n",
    "            file_name = f\"HyDE={hyde_n}\"\n",
    "        else:\n",
    "            file_name = file.split(\"-\")[-1].split(\".\")[0]\n",
    "            \n",
    "        results[\"Topic\"] = topics\n",
    "\n",
    "        for topic in topics:\n",
    "            top_n = TOPICS_UNDER_10K[topic] if under_10k else top_n\n",
    "            ids = set(df[df[\"topic\"] == topic].head(top_n)[\"id\"].tolist())\n",
    "            cps = eval_df[eval_df[\"topic\"] == topic][\"id\"].tolist()\n",
    "            recall = len(ids.intersection(set(cps))) / len(cps)\n",
    "            results[file_name].append(recall)\n",
    "\n",
    "    return pd.DataFrame(results).round(3)\n",
    "\n",
    "\n",
    "def show_results(\n",
    "    files: list[str], under_10k: bool = False, top_n: int = 10_000\n",
    ") -> None:\n",
    "    df = parse_results(files, under_10k, top_n)\n",
    "    df[\"Topic\"] = df[\"Topic\"].apply(lambda x: shorten(x, width=25, placeholder=\"...\"))\n",
    "    fig = px.imshow(\n",
    "        df.set_index(\"Topic\").T,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        aspect=\"auto\",\n",
    "        text_auto=\".2f\",\n",
    "        labels=dict(x=\"Topic\", y=\"Model\"),\n",
    "    )\n",
    "    if under_10k:\n",
    "        sample_size = np.full(df.shape, 10_000).T\n",
    "        for i, topic in enumerate(df[\"Topic\"].unique()):\n",
    "            n = TOPICS_UNDER_10K[topic] if topic in TOPICS_UNDER_10K else 10_000\n",
    "            sample_size[:, i] = n\n",
    "        fig.update_traces(customdata=sample_size)\n",
    "        fig.update_traces(\n",
    "            hovertemplate=\"Sample Size: %{customdata}<br>Recall: %{z:.3f}\"\n",
    "        )\n",
    "\n",
    "    mean_recall = df.mean(axis=0, numeric_only=True).values\n",
    "    print(f\"HyDe=0: {mean_recall[0]:.3f}\")\n",
    "    print(f\"HyDe=1: {mean_recall[1]:.3f}\")\n",
    "    print(f\"HyDe=2: {mean_recall[2]:.3f}\")\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the worst CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_10k = False\n",
    "top_n = 10_000\n",
    "worst_files = glob(\"ablation/hyde/worst/All_*.parquet\")\n",
    "show_results(worst_files, under_10k, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using an average CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_files = glob(\"ablation/hyde/average/All_*.parquet\")\n",
    "show_results(average_files, under_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the best CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_files = glob(\"ablation/hyde/best/All_*.parquet\")\n",
    "show_results(best_files, under_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the random CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_files = glob(\"ablation/hyde/random/*.parquet\")\n",
    "show_results(random_files, under_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the final evaluation using 5 RQs, HyDE 1 and a random CP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_files_no_hyde = glob(\"ablation/final/*.parquet\")\n",
    "show_results(random_files_no_hyde, under_10k) # Ignore the output of HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.io import read_json\n",
    "from utils import save_plot\n",
    "layout = dict(\n",
    "    # width=1300,\n",
    "    # height=700,\n",
    "    xaxis_tickangle=-45,\n",
    "    xaxis_tickfont_size=20,\n",
    "    yaxis_tickfont_size=20,\n",
    "    yaxis_title=\"Trial Nr.\",\n",
    "    yaxis_title_font_size=30,\n",
    "    xaxis_title_font_size=30,\n",
    ")\n",
    "fig = read_json(\"test.json\")\n",
    "save_plot(fig, \"post_optimization_10_trials\", layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k():\n",
    "    results = {\n",
    "        \"CP Type\": [],\n",
    "        \"Recall\": [],\n",
    "        \"Top N\": [],\n",
    "    }\n",
    "    options = [\n",
    "        (\"Worst CP\", worst_files),\n",
    "        (\"Average CP\", average_files),\n",
    "        (\"Best CP\", best_files),\n",
    "        (\"Random CP\",  random_files_no_hyde)\n",
    "    ]\n",
    "    for name, files in tqdm(options):\n",
    "        files_recall = []\n",
    "        results[\"CP Type\"].extend([name]* 101)\n",
    "        results[\"Top N\"].extend(list(range(0, 10100, 100)))\n",
    "        for file in tqdm(files, leave=False):\n",
    "            df = pl.read_parquet(file)\n",
    "            topics = df.select(\"topic\").unique().to_numpy().flatten()\n",
    "\n",
    "            topics_recall = []\n",
    "            for topic in topics:\n",
    "                cps = set(eval_df[eval_df[\"topic\"] == topic][\"id\"].tolist())\n",
    "                topic_df = df.filter(pl.col(\"topic\") == topic)\n",
    "                steps_recall = []\n",
    "\n",
    "                for i in range(1, 10101, 100):\n",
    "                    found_cps = set(topic_df.head(i).select(\"id\").to_numpy().flatten().tolist())\n",
    "                    recall = len(cps.intersection(found_cps)) / len(cps)\n",
    "                    steps_recall.append(recall)\n",
    "\n",
    "                topics_recall.append(steps_recall)\n",
    "            files_recall.append(np.mean(topics_recall, axis=0))\n",
    "        results[\"Recall\"].extend(np.mean(files_recall, axis=0))\n",
    " \n",
    "    return results\n",
    "# from utils import save_data\n",
    "# results = recall_at_k()\n",
    "# save_data(pd.DataFrame(results), \"recall_change_over_topn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
