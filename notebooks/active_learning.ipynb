{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Generator, Literal, Optional, Sequence\n",
    "\n",
    "from asreview import ASReviewData, ASReviewProject, open_state  # noqa: E402\n",
    "from asreview.models.classifiers import NaiveBayesClassifier  # noqa: E402\n",
    "from asreview.models.feature_extraction import Tfidf  # noqa: E402\n",
    "from asreviewcontrib.insights.metrics import recall  # noqa: E402\n",
    "from asreview.models.balance import DoubleBalance  # noqa: E402\n",
    "from asreview.models.query import MaxQuery  # noqa: E402\n",
    "from asreview.review import ReviewSimulate  # noqa: E402\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from sklearnex import patch_sklearn, set_config\n",
    "# gpu\n",
    "set_config(target_offload=\"gpu\")\n",
    "patch_sklearn()\n",
    "from sklearn.svm import SVC  # noqa: E402\n",
    "from sentence_transformers import util # noqa: E402\n",
    "from lightgbm.sklearn import LGBMClassifier # noqa: E402\n",
    "from catboost import CatBoostClassifier, Pool  # noqa: E402\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  # noqa: E402\n",
    "\n",
    "from notebooks.ablations.utils import TOPICS_UNDER_5K, TOPICS_UNDER_10K # noqa: E402\n",
    "from utils import DataReader # noqa: E402\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int = 64,\n",
    "        output_dim: int = 1,\n",
    "        dropout_rate: float = 0.5,\n",
    "        weight_decay_rate: float = 1e-3,\n",
    "    ):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.parameters(), weight_decay=weight_decay_rate\n",
    "        )\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.sigmoid(self.model(x))\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray, epochs=150):\n",
    "        self.train()\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32).to(self.device).float()\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.forward(x_tensor)\n",
    "            loss = self.loss_fn(outputs, y_tensor.view(-1, 1))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x: np.ndarray) -> np.ndarray:\n",
    "        self.eval()\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(x_tensor)\n",
    "            return outputs.cpu().numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pl.read_excel(\"data/eval_cps.xlsx\")\n",
    "data = pl.read_parquet(\"ablation/hyde/best/All_HYDE0.parquet\")\n",
    "topic_items = {}\n",
    "for topic in data.select(\"topic\").unique().to_numpy().flatten():\n",
    "    topic_items[topic] = {\n",
    "        \"id\": data.filter(pl.col(\"topic\") == topic).select(\"id\").to_numpy().flatten().tolist(),\n",
    "        \"score\": data.filter(pl.col(\"topic\") == topic).select(\"score\").to_numpy().flatten().tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df: pl.DataFrame, new=False):\n",
    "    path = \"ablation/active_learning/embeddings.parquet\"\n",
    "    if os.path.exists(path) and not new:\n",
    "        return pl.read_parquet(path)\n",
    "\n",
    "    work_ids = list(set(df.select(\"id\").to_numpy().flatten().tolist()))\n",
    "    reader = DataReader()\n",
    "    results = {\"id\": [], \"embedding\": [], \"title\": [], \"abstract\": []}\n",
    "    for batch in reader.scan_batches():\n",
    "        items = (\n",
    "            batch.filter(pl.col(\"id\").is_in(work_ids))\n",
    "            .select(\"id\", \"embedding\", \"title\", \"abstract\")\n",
    "            .collect()\n",
    "        )\n",
    "        results[\"id\"].extend(items.select(\"id\").to_numpy().flatten().tolist())\n",
    "        results[\"embedding\"].extend(items.select(\"embedding\").to_numpy().flatten().tolist()\n",
    "        )\n",
    "        results[\"title\"].extend(items.select(\"title\").to_numpy().flatten().tolist())\n",
    "        results[\"abstract\"].extend(items.select(\"abstract\").to_numpy().flatten().tolist()\n",
    "        )\n",
    "    df = pl.DataFrame(results)\n",
    "    if not new:\n",
    "        df.write_parquet(\"ablation/active_learning/embeddings.parquet\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_data(df: pl.DataFrame, topic: str, topic_items: dict[dict]) -> pl.DataFrame:\n",
    "    cps_id = (\n",
    "        eval_df.filter(pl.col(\"topic\") == topic)\n",
    "        .select(\"id\")\n",
    "        .to_numpy()\n",
    "        .flatten()\n",
    "        .tolist()\n",
    "    )\n",
    "    df = (\n",
    "        df.filter(pl.col(\"id\").is_in(topic_items[topic][\"id\"]))\n",
    "        .with_columns(\n",
    "            pl.when(pl.col(\"id\").is_in(cps_id)).then(1).otherwise(0).alias(\"label\")\n",
    "        )\n",
    "        .unique([\"title\", \"abstract\"])\n",
    "    )\n",
    "    scores_df = pl.DataFrame(\n",
    "        {\"id\": topic_items[topic][\"id\"], \"score\": topic_items[topic][\"score\"]}\n",
    "    )\n",
    "    df = df.join(scores_df, \"id\").rename({\"id\": \"url\"}).sort(\"score\", descending=True)\n",
    "    return df\n",
    "\n",
    "def parse_data(\n",
    "    df: pl.DataFrame, topics: dict[dict[str, list[str]]] = topic_items\n",
    ") -> Generator[tuple[str, pl.DataFrame, tuple, tuple, tuple], None, None]:\n",
    "    \"\"\"\n",
    "    Parse the data into a generator of tuples containing corpus, positive publications, and negative publications.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pl.DataFrame\n",
    "        The input dataframe containing the data to be parsed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Generator[tuple, None, None]\n",
    "        A generator yielding tuples of (corpus, positive publications, negative publications).\n",
    "    \"\"\"\n",
    "    pbar = tqdm(topics)\n",
    "    for topic in pbar:\n",
    "        pbar.set_description(topic)\n",
    "        topic_df = get_topic_data(df, topic, topics)\n",
    "        corpus_embeddings = np.vstack(topic_df.select(\"embedding\").to_numpy().flatten())\n",
    "        ids = topic_df.select(\"url\").to_numpy().flatten().tolist()\n",
    "        corpus = tuple(zip(ids, corpus_embeddings))\n",
    "        positive_embeddings = np.vstack(\n",
    "            topic_df.filter(pl.col(\"label\") == 1)\n",
    "            .select(\"embedding\")\n",
    "            .to_numpy()\n",
    "            .flatten()\n",
    "        )\n",
    "        positive_ids = (\n",
    "            topic_df.filter(pl.col(\"label\") == 1)\n",
    "            .select(\"url\")\n",
    "            .to_numpy()\n",
    "            .flatten()\n",
    "            .tolist()\n",
    "        )\n",
    "        positive_pubs = tuple(zip(positive_ids, positive_embeddings))\n",
    "\n",
    "        negative_embeddings = np.vstack(\n",
    "            topic_df.filter(pl.col(\"label\") == 0)\n",
    "            .select(\"embedding\")\n",
    "            .to_numpy()\n",
    "            .flatten()\n",
    "        )\n",
    "        negative_ids = (\n",
    "            topic_df.filter(pl.col(\"label\") == 0)\n",
    "            .select(\"url\")\n",
    "            .to_numpy()\n",
    "            .flatten()\n",
    "            .tolist()\n",
    "        )\n",
    "        negative_pubs = tuple(zip(negative_ids, negative_embeddings))\n",
    "\n",
    "        yield topic, topic_df, corpus, positive_pubs, negative_pubs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vector_strategy(\n",
    "    positive_vectors: Sequence[np.ndarray],\n",
    "    negative_vectors: Optional[Sequence[np.ndarray]] = None\n",
    ") -> np.ndarray:\n",
    "\n",
    "    if len(positive_vectors) == 0:\n",
    "        raise ValueError(\"At least one positive vector is required.\")\n",
    "\n",
    "    if positive_vectors.ndim == 1:\n",
    "        positive_vectors = positive_vectors.reshape(1, -1)\n",
    "    pos_stack = np.stack(positive_vectors)\n",
    "    avg_pos = pos_stack.mean(axis=0)\n",
    "\n",
    "    if negative_vectors is not None:\n",
    "        if len(negative_vectors) == 0:\n",
    "            raise ValueError(\"Negative vectors sequence provided but empty.\")\n",
    "        \n",
    "        if negative_vectors.ndim == 1:\n",
    "            negative_vectors = negative_vectors.reshape(1, -1)\n",
    "\n",
    "        neg_stack = np.stack(negative_vectors)\n",
    "        avg_neg = neg_stack.mean(axis=0)\n",
    "\n",
    "        search_vec = (avg_pos * 2) - avg_neg\n",
    "    else:\n",
    "        search_vec = avg_pos\n",
    "\n",
    "    return search_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similiar_pubs(\n",
    "    query_vector: np.ndarray,\n",
    "    search_embeddings: np.ndarray,\n",
    "    search_ids: list[str],\n",
    ") -> str | None:\n",
    "    hits = util.semantic_search(query_vector, search_embeddings, top_k=1)\n",
    "    max_idx = hits[0][0][\"corpus_id\"]\n",
    "    return search_ids[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability=True, verbose=False)\n",
    "\n",
    "def predict_next_hit(\n",
    "    positive_vectors: Sequence[np.ndarray],\n",
    "    negative_vectors: Optional[Sequence[np.ndarray]],\n",
    "    search_embeddings: np.ndarray,\n",
    "    search_ids: list[str],\n",
    "    prediction_method: Literal[\"catboost\", \"mlp\", \"lgbm\", \"avg-vector\", \"svm\", \"lda\"] = \"avg-vector\",\n",
    "):\n",
    "    train_x = np.vstack([positive_vectors, negative_vectors])\n",
    "    train_y = ([1] * positive_vectors.shape[0]) + ([0] * negative_vectors.shape[0])\n",
    "    if prediction_method == \"catboost\":\n",
    "        train_pool = Pool(train_x, train_y)\n",
    "        model = CatBoostClassifier(iterations=50, verbose=False)\n",
    "        model.fit(train_pool)\n",
    "        y_preds = model.predict_proba(search_embeddings)[:, 1].flatten()\n",
    "        \n",
    "    elif prediction_method == \"mlp\":\n",
    "        model = MLPClassifier(input_dim=1024)\n",
    "        model = model.fit(train_x, train_y)\n",
    "        y_preds = model.predict_proba(search_embeddings)\n",
    "\n",
    "    elif prediction_method == \"lgbm\":\n",
    "        model = LGBMClassifier(verbose=-1)\n",
    "        model.fit(train_x, train_y)\n",
    "        y_preds = model.predict_proba(search_embeddings)[:,1].flatten()\n",
    "    \n",
    "    elif prediction_method == \"svm\":\n",
    "        if train_x.shape[0] % 10 == 0 or train_x.shape[0] == 2:\n",
    "            SVM.fit(train_x, train_y)\n",
    "        y_preds = SVM.predict_proba(search_embeddings)[:,1].flatten()\n",
    "    \n",
    "    elif prediction_method == \"lda\":\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "        model.fit(train_x, train_y)\n",
    "        y_preds = model.predict_proba(search_embeddings)[:,1].flatten()\n",
    "\n",
    "    elif prediction_method == \"avg-vector\":\n",
    "        query_vector = average_vector_strategy(positive_vectors, negative_vectors)\n",
    "        hit = get_similiar_pubs(query_vector, search_embeddings, search_ids)\n",
    "        return hit\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {prediction_method}\")\n",
    "\n",
    "    best_idx = np.argmax(y_preds)\n",
    "    return search_ids[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(\n",
    "    positive_pubs: list[tuple[str, np.ndarray]],\n",
    "    negative_pubs: list[tuple[str, np.ndarray]],\n",
    "    corpus: list[tuple[str, np.ndarray]],\n",
    "    topic: str,\n",
    "    max_iterations: Optional[int] = 10_000,\n",
    "    predicition_method: Literal[\"avg-vector\", \"catboost\", \"mlp\", \"lgbm\", \"svm\", \"lda\"] = \"avg-vector\",\n",
    "    verbose: bool = False,\n",
    ") -> list[float]:\n",
    "    # --- Pre-processing ---\n",
    "    corpus_dict = {item[0]: item[1] for item in corpus}\n",
    "    all_corpus_ids = set(corpus_dict.keys())\n",
    "\n",
    "    positive_target_ids = {i[0] for i in positive_pubs}\n",
    "    negative_target_ids = {i[0] for i in negative_pubs}\n",
    "\n",
    "    # Initialize selected sets with the first element\n",
    "    selected_positive_set = {positive_pubs[0][0]}\n",
    "    selected_negative_set = {negative_pubs[0][0]}\n",
    "\n",
    "    # Initialize set of IDs available for searching\n",
    "    available_ids = all_corpus_ids - selected_positive_set - selected_negative_set\n",
    "    results = []\n",
    "    idx = 0\n",
    "\n",
    "    topic_actual_cps = eval_df.filter(pl.col(\"topic\")==topic).shape[0]\n",
    "    print(f\"Starting stimulation. Target: {topic_actual_cps} positive pubs.\")\n",
    "    if len(positive_target_ids) != topic_actual_cps:\n",
    "        print(\"The Top@K retreived CPs is not equal to the actual CPS. Consider increasing K.\")\n",
    "        print(f\"Target: {len(positive_target_ids)} CPS. Actual: {topic_actual_cps} CPS.\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Initial positive: {selected_positive_set}\")\n",
    "        print(f\"Initial negative: {selected_negative_set}\")\n",
    "        print(f\"Available for search: {len(available_ids)} pubs.\")\n",
    "\n",
    "    while not positive_target_ids.issubset(selected_positive_set):\n",
    "        pos_vec_list = [corpus_dict[pid] for pid in selected_positive_set]\n",
    "        neg_vec_list = [corpus_dict[nid] for nid in selected_negative_set]\n",
    "\n",
    "        # Check if lists are empty before vstack\n",
    "        positive_vectors = np.vstack(pos_vec_list)\n",
    "        negative_vectors = np.vstack(neg_vec_list)\n",
    "\n",
    "        search_ids = list(available_ids)\n",
    "        search_embeddings = np.vstack([corpus_dict[id] for id in search_ids])\n",
    "\n",
    "  \n",
    "        hit = predict_next_hit(\n",
    "            positive_vectors,\n",
    "            negative_vectors,\n",
    "            search_embeddings,\n",
    "            search_ids,\n",
    "            prediction_method=predicition_method,\n",
    "        )\n",
    "\n",
    "        # Remove hit from available set\n",
    "        available_ids.remove(hit)\n",
    "\n",
    "        if hit in negative_target_ids:\n",
    "            selected_negative_set.add(hit)\n",
    "        else:\n",
    "            selected_positive_set.add(hit)\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "        recall = len(selected_positive_set) / topic_actual_cps #len(positive_target_ids)\n",
    "        results.append(recall)\n",
    "\n",
    "        if idx % 50 == 0 and verbose:\n",
    "            print(\n",
    "                f\"Iteration: {idx}, Recall: {round(recall, 3)}, Available: {len(available_ids)}\"\n",
    "            )\n",
    "\n",
    "        if idx >= max_iterations:\n",
    "            print(f\"Stopping: Reached max iterations ({max_iterations})\")\n",
    "            break\n",
    "\n",
    "    print(\n",
    "        f\"Final Pos Found: {len(selected_positive_set)}, Iterations: {len(selected_negative_set)}\"\n",
    "    )\n",
    "\n",
    "    # If the results are less than max_iterations long, then fill the rest with recall of 1.\n",
    "    if len(results) < max_iterations:\n",
    "        for i in range(len(results), max_iterations):\n",
    "            results.append(1.0)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_baseline(\n",
    "    positive_pubs: list[tuple[str, np.ndarray]],\n",
    "    corpus: list[tuple[str, np.ndarray]],\n",
    "):\n",
    "    n_cps = len(positive_pubs)\n",
    "    positive_ids = [i[0] for i in positive_pubs]\n",
    "    corpus_ids = [i[0] for i in corpus]\n",
    "    corpus_df = pl.DataFrame({\"url\": corpus_ids})\n",
    "\n",
    "    results = []\n",
    "    for i in range(10_000):\n",
    "        recall = (\n",
    "            len(\n",
    "                set(\n",
    "                    corpus_df.head(i).select(\"url\").to_numpy().flatten().tolist()\n",
    "                ).intersection(set(positive_ids))\n",
    "            )\n",
    "            / n_cps\n",
    "        )\n",
    "        results.append(recall)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_asreview(topic_df: pl.DataFrame) -> list[float]:\n",
    "    train_model = NaiveBayesClassifier()\n",
    "    query_model = MaxQuery()\n",
    "    balance_model = DoubleBalance()\n",
    "    feature_model = Tfidf()\n",
    "\n",
    "    temp_dir = Path(\"tmp_data\")\n",
    "    temp_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    name = str(uuid4())\n",
    "    project_path = Path(temp_dir, name)\n",
    "    data_path = Path(project_path, \"api_simulation\", \"data\", \"topic_data.csv\")\n",
    "    results_path = Path(project_path, \"results.asreview\")\n",
    "    project = ASReviewProject.create(\n",
    "        project_path=project_path / \"api_simulation\",\n",
    "        project_id=name,\n",
    "        project_mode=\"simulate\",\n",
    "        project_name=name,\n",
    "    )\n",
    "    topic_df.select(\"url\", \"title\", \"abstract\", \"label\").write_csv(data_path)\n",
    "    data_obj = ASReviewData.from_file(data_path)\n",
    "    reviewer = ReviewSimulate(\n",
    "        as_data=data_obj,\n",
    "        model=train_model,\n",
    "        query_model=query_model,\n",
    "        balance_model=balance_model,\n",
    "        feature_model=feature_model,\n",
    "        n_instances=10,\n",
    "        project=project,\n",
    "        n_prior_included=1,\n",
    "        n_prior_excluded=1,\n",
    "    )\n",
    "    reviewer.review()\n",
    "    project.mark_review_finished()\n",
    "    project.export(results_path)\n",
    "    with open_state(results_path) as state_obj:\n",
    "        recalls = [recall(state_obj, i) for i in tqdm(np.linspace(0, 1, 10000), leave=False)]\n",
    "    \n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = get_data(data)\n",
    "    results = {\n",
    "        # \"Baseline\": [],\n",
    "        # \"Avg. Vector\": [],\n",
    "        # \"Asreview\": [],\n",
    "        # \"Multilayer Perceptron\": [],\n",
    "        \"SVM\": [],\n",
    "    }\n",
    "    method_names = {\n",
    "        \"mlp\": \"Multilayer Perceptron\",\n",
    "        \"avg-vector\": \"Avg. Vector\",\n",
    "        \"svm\": \"SVM\",\n",
    "    }\n",
    "    for topic, topic_df, corpus, positive_pubs, negative_pubs in parse_data(df):\n",
    "        # baseline_result = simulate_baseline(positive_pubs, corpus)\n",
    "        # asr_results = simulate_asreview(topic_df)\n",
    "        # results[\"Baseline\"].append(baseline_result)\n",
    "        # results[\"Asreview\"].append(asr_results)\n",
    "        \n",
    "        for method in [\"svm\"]:\n",
    "            result = simulate(\n",
    "                positive_pubs,\n",
    "                negative_pubs,\n",
    "                corpus,\n",
    "                topic,\n",
    "                predicition_method=method,\n",
    "                verbose=True,\n",
    "            )\n",
    "            results[method_names[method]].append(result)\n",
    "\n",
    "    return results\n",
    "\n",
    "from utils import save_data\n",
    "results = run()\n",
    "aggergated_results = {k: np.mean(v, axis=0) for k, v in results.items()}\n",
    "plot_df = pl.DataFrame(aggergated_results).with_row_index(\"Percent Reviewed\").to_pandas()\n",
    "save_data(plot_df, \"active_learnning_svm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_under_5k(files: list[str]):\n",
    "    results = defaultdict(list)\n",
    "    for file in tqdm(files):\n",
    "        data = pl.read_parquet(file)\n",
    "        df = get_data(data, new=False)\n",
    "        topics = {}\n",
    "        for topic in TOPICS_UNDER_5K:\n",
    "            temp = data.filter(pl.col(\"topic\") == topic)\n",
    "            topics[topic] = {\n",
    "                \"id\": temp.select(\"id\").to_numpy().flatten().tolist(),\n",
    "                \"score\": list(range(temp.shape[0]))[::-1]\n",
    "            }\n",
    "\n",
    "        file_results = defaultdict(list)\n",
    "        for i, (topic, topic_df, corpus, positive_pubs, negative_pubs) in enumerate(\n",
    "            parse_data(df, topics)\n",
    "        ):\n",
    "            top_n = TOPICS_UNDER_5K[topic]\n",
    "            print(f\"{topic}: {top_n}\")\n",
    "            result = simulate(\n",
    "                # topic_df,\n",
    "                positive_pubs,\n",
    "                negative_pubs,\n",
    "                corpus,\n",
    "                topic,\n",
    "                predicition_method=\"svm\",   \n",
    "                verbose=False,\n",
    "                max_iterations=top_n,\n",
    "            )[:top_n]\n",
    "            file_results[topic].extend(result)\n",
    "            print(\"\\n\\n\")\n",
    "        for k, v in file_results.items():\n",
    "            results[k].append(max(v))\n",
    "    return results\n",
    "\n",
    "# from utils import save_data\n",
    "files = glob(\"ablation/final/*.parquet\")\n",
    "results = simulate_under_5k(files)\n",
    "averaged_results = {k:np.mean(v).item() for k,v in results.items()}\n",
    "averaged_results = pl.DataFrame(averaged_results).to_pandas() \n",
    "# save_data(averaged_results, \"activate_learning_under_5k_asreview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"PaperSeek-Report/data/active_learning_under_5k.csv\")\n",
    "clms = df.columns[1:]\n",
    "df.with_columns(mean=pl.mean_horizontal(clms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
